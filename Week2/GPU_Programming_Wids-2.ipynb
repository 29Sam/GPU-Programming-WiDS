{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDMWcFTDZ_FE",
        "outputId": "36c56adf-c98f-45b1-a1a3-a0b763e28e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLbgYO8WanqG",
        "outputId": "7aa4ab7f-66fb-4bf6-a34b-1a7147296faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 24 12:51:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(5000, 5000, device=\"cuda\")\n",
        "y = torch.randn(5000, 5000, device=\"cuda\")\n",
        "z = x @ y\n",
        "print(z.device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6C2eLWKa2L-",
        "outputId": "1732aced-5f2c-4f20-c4ae-27ac02318316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atEDVyMAa4pm",
        "outputId": "8c977d33-f661-4422-9975-a8ab5176f355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 24 12:53:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0             25W /   70W |     518MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git\n",
        "%cd cuda-samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfdz96hK1xSX",
        "outputId": "41e5dcc6-c983-4042-e288-5c490df64fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 30467, done.\u001b[K\n",
            "remote: Total 30467 (delta 0), reused 0 (delta 0), pack-reused 30467 (from 1)\u001b[K\n",
            "Receiving objects: 100% (30467/30467), 137.01 MiB | 12.70 MiB/s, done.\n",
            "Resolving deltas: 100% (27067/27067), done.\n",
            "Updating files: 100% (2052/2052), done.\n",
            "/content/cuda-samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y cmake\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM-bdwW22BEe",
        "outputId": "c45709ae-bdbf-4e24-81bb-c02db35a1f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir build"
      ],
      "metadata": {
        "id": "5G04bi472HYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd build\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1UGsBMi2UIt",
        "outputId": "0adae520-a836-4b01-894a-47f526132119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cuda-samples/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ4QVb0P2_iq",
        "outputId": "88801223-61a9-48a0-cf7b-d5a2b47847a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cuda-samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find Samples -type d -name \"*vectorAdd*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fTqzU1m3B3g",
        "outputId": "69680543-3325-456d-c71e-2152f90194fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples/0_Introduction/vectorAdd_nvrtc\n",
            "Samples/0_Introduction/vectorAdd\n",
            "Samples/0_Introduction/vectorAddDrv\n",
            "Samples/0_Introduction/vectorAddMMAP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -I../../../Common -o vectorAdd\n"
      ],
      "metadata": {
        "id": "z5Vm5lOj4Whn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu3h1q7t4lo0",
        "outputId": "9237d8ba-68b1-4eeb-b79c-5e48a6631093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CMakeLists.txt\tREADME.md  vectorAdd  vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzZI395T4oKH",
        "outputId": "67fd7b2d-f6ee-4b43-84d2-b324ce2826ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Failed to launch vectorAdd kernel (error code the provided PTX was compiled with an unsupported toolchain.)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -I../../../Common --gpu-architecture=native -o vectorAdd\n"
      ],
      "metadata": {
        "id": "ifmC2-b84xJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNJOxQa-40D-",
        "outputId": "184d17c2-e992-4c34-fc4e-7bb412d9a4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/cuda-samples/Samples/0_Introduction/matrixMul\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK6GPdWa5YxE",
        "outputId": "0c979420-a9d8-4fa8-d72d-6e57bed7847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cuda-samples/Samples/0_Introduction/matrixMul\n",
            "CMakeLists.txt\tmatrixMul.cu  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrixMul.cu \\\n",
        "-I../../../Common \\\n",
        "--gpu-architecture=native \\\n",
        "-o matrixMul\n"
      ],
      "metadata": {
        "id": "xiCZHueG7Mq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrixMul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucU871i47VvY",
        "outputId": "4049537a-c1ff-4f98-96fa-1e970092fc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matrix Multiply Using CUDA] - Starting...\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "MatrixA(320,320), MatrixB(640,320)\n",
            "Computing result using CUDA Kernel...\n",
            "done\n",
            "Performance= 410.85 GFlop/s, Time= 0.319 msec, Size= 131072000 Ops, WorkgroupSize= 1024 threads/block\n",
            "Checking computed result for correctness: Result = PASS\n",
            "\n",
            "NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pwd\n",
        "!mkdir -p week2\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da7Dsfoy_dLg",
        "outputId": "8afd77d9-89e6-4113-e7b5-a8a78e247bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "cuda-samples  sample_data  week2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int N = 1024;\n",
        "    std::vector<float> h_A(N), h_B(N), h_C(N);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = 2.0f * i;\n",
        "    }\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * sizeof(float));\n",
        "    cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    int threads = 256;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "    vectorAdd<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = h_A[i] + h_B[i];\n",
        "        if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "            std::cout << \"FAIL at \" << i << std::endl;\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"Vector Add: PASS\" << std::endl;\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6TQTXIDZIN",
        "outputId": "ab74abb1-e99d-45a7-9016-81689fb8f7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu --gpu-architecture=native -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTmOhd1ND6XF",
        "outputId": "1fb0d594-e829-4d03-b28e-9585b8c9cd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Add: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCTPn9XuETWh",
        "outputId": "9b23a083-f6ae-4eca-86fe-eae19712a9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multiply_scale.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void multiplyScale(const float* A, const float* B, float* C, float alpha, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = alpha * A[i] * B[i];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int N = 1024;\n",
        "    float alpha = 2.0f;\n",
        "\n",
        "    std::vector<float> h_A(N), h_B(N), h_C(N);\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = i * 0.5f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threads = 256;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "    multiplyScale<<<blocks, threads>>>(d_A, d_B, d_C, alpha, N);\n",
        "\n",
        "    cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = alpha * h_A[i] * h_B[i];\n",
        "        if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "            std::cout << \"FAIL at index \" << i << std::endl;\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"Multiply-and-Scale: PASS\" << std::endl;\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy6jc9c_EWBx",
        "outputId": "2b100068-35db-4e69-d3d1-274527e3d2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing multiply_scale.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc multiply_scale.cu --gpu-architecture=native -o multiply_scale\n",
        "!./multiply_scale\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKp9yfCTEbXf",
        "outputId": "e4cfee10-2bd7-4486-fa5d-9c18eb4bb77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiply-and-Scale: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7-yuPCrEiNm",
        "outputId": "274899b6-12b2-4f53-b60a-af2558811907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile relu.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void reluKernel(const float* A, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = (A[i] > 0.0f) ? A[i] : 0.0f;\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int N = 1024;\n",
        "    std::vector<float> h_A(N), h_C(N);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i - 512;   // some negatives, some positives\n",
        "    }\n",
        "    float *d_A, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * sizeof(float));\n",
        "    cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    int threads = 256;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "    reluKernel<<<blocks, threads>>>(d_A, d_C, N);\n",
        "    cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = std::max(h_A[i], 0.0f);\n",
        "        if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "            std::cout << \"FAIL at index \" << i << std::endl;\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"ReLU: PASS\" << std::endl;\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z86gpVvIEjmq",
        "outputId": "a5a4cb6c-5576-4e6c-bf93-084d9a4a558f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing relu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc relu.cu --gpu-architecture=native -o relu\n",
        "!./relu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQk6C5AhEo2B",
        "outputId": "d1619511-c509-4abb-ddbc-b2f9217d4eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ignore**"
      ],
      "metadata": {
        "id": "9Fdo7kYkx5w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMzhCfcQEsMt",
        "outputId": "cfd8f95b-36ac-49c4-deec-f0e133a193b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda-samples\tmultiply_scale.cu  relu.cu\tvector_add     week2\n",
            "multiply_scale\trelu\t\t   sample_data\tvector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd week2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yufNxaFB47",
        "outputId": "56fd42b9-1727-41e5-9195-009eb25aecc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/week2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "Tw5T8vKjFDaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r week2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wATwmaO0FNS3",
        "outputId": "84157005-70d9-4dde-fb72-a060e1e3380b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'week2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYVq8FlbFPIm",
        "outputId": "6149f5b0-352b-415e-bd17-7040eefebbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r week2\n"
      ],
      "metadata": {
        "id": "kVIk9VEzFQar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm vector_add multiply_scale relu\n"
      ],
      "metadata": {
        "id": "VoGgR1piFRm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA1H1nxOFT6R",
        "outputId": "d2bf8caa-463a-4c4c-e1ea-9261209327b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda-samples  multiply_scale.cu  relu.cu  sample_data  vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj1ZTvJjMeJ9",
        "outputId": "09255107-44d8-4d0b-bd47-feca3146cb16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "cuda-samples  multiply_scale.cu  relu.cu  sample_data  vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task2**\n"
      ],
      "metadata": {
        "id": "tBSLCBJTW7II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int N = 10000000;\n",
        "    std::vector<float> h_A(N), h_B(N), h_C(N);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = 2.0f * i;\n",
        "    }\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * sizeof(float));\n",
        "    cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    int threads = 32;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "    vectorAdd<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = h_A[i] + h_B[i];\n",
        "        if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "            std::cout << \"FAIL at \" << i << std::endl;\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"Vector Add: PASS\" << std::endl;\n",
        "    std::cout << \"N = \" << N << std::endl;\n",
        "    std::cout << \"blockDim.x = \" << threads << std::endl;\n",
        "    std::cout << \"gridDim.x = \" << blocks << std::endl;\n",
        "    std::cout << \"Total threads launched = \" << blocks * threads << std::endl;\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIRvZvg6Pm0V",
        "outputId": "aa5f4fae-bfd1-47c8-8a97-6a0fd7d93178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu --gpu-architecture=native -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb9X8SY5SVSX",
        "outputId": "a5afec12-ace4-423f-8bcc-3427fe71b2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Add: PASS\n",
            "N = 10000000\n",
            "blockDim.x = 32\n",
            "gridDim.x = 312500\n",
            "Total threads launched = 10000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task3**"
      ],
      "metadata": {
        "id": "M6qm9szXfwmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation Table1**"
      ],
      "metadata": {
        "id": "eMnEYxaBxvUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int N = 1000;\n",
        "    std::vector<float> h_A(N), h_B(N), h_C(N);\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = 2.0f * i;\n",
        "    }\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * sizeof(float));\n",
        "    cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    int threads = 32;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    vectorAdd<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"Kernel execution time (ms): \"\n",
        "              << milliseconds << std::endl;\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = h_A[i] + h_B[i];\n",
        "        if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "            std::cout << \"FAIL at \" << i << std::endl;\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"Vector Add: PASS\" << std::endl;\n",
        "    std::cout << \"N = \" << N << std::endl;\n",
        "    std::cout << \"blockDim.x = \" << threads << std::endl;\n",
        "    std::cout << \"gridDim.x = \" << blocks << std::endl;\n",
        "    std::cout << \"Total threads launched = \" << blocks * threads << std::endl;\n",
        "\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC22XQQXfyg4",
        "outputId": "f01a5cce-c537-4a6a-ce2f-07d8e7ef0328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu --gpu-architecture=native -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faRL0u7Lg6qc",
        "outputId": "9be3fdd7-614c-48a1-fbe1-96f55cc7e71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel execution time (ms): 0.102048\n",
            "Vector Add: PASS\n",
            "N = 1000\n",
            "blockDim.x = 32\n",
            "gridDim.x = 32\n",
            "Total threads launched = 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation Table2**"
      ],
      "metadata": {
        "id": "eMLOaqWwxqD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int Ns[] = {1000, 100000, 10000000};\n",
        "    int blockSizes[] = {32, 128, 256, 512};\n",
        "    for (int ni = 0; ni < 3; ni++) {\n",
        "        int N = Ns[ni];\n",
        "        std::vector<float> h_A(N), h_B(N), h_C(N);\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            h_A[i] = i * 1.0f;\n",
        "            h_B[i] = 2.0f * i;\n",
        "        }\n",
        "        float *d_A, *d_B, *d_C;\n",
        "        cudaMalloc(&d_A, N * sizeof(float));\n",
        "        cudaMalloc(&d_B, N * sizeof(float));\n",
        "        cudaMalloc(&d_C, N * sizeof(float));\n",
        "        cudaMemcpy(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        for (int bi = 0; bi < 4; bi++) {\n",
        "            int threads = blockSizes[bi];\n",
        "            int blocks = (N + threads - 1) / threads;\n",
        "            cudaEvent_t start, stop;\n",
        "            cudaEventCreate(&start);\n",
        "            cudaEventCreate(&stop);\n",
        "            cudaEventRecord(start);\n",
        "            vectorAdd<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "            cudaEventRecord(stop);\n",
        "            cudaEventSynchronize(stop);\n",
        "            float milliseconds = 0;\n",
        "            cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "            cudaMemcpy(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "            bool pass = true;\n",
        "            for (int i = 0; i < N; i++) {\n",
        "                float expected = h_A[i] + h_B[i];\n",
        "                if (std::fabs(h_C[i] - expected) > 1e-5) {\n",
        "                    pass = false;\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            std::cout << \"----------------------------------\\n\";\n",
        "            std::cout << \"N = \" << N << \"\\n\";\n",
        "            std::cout << \"blockDim.x = \" << threads << \"\\n\";\n",
        "            std::cout << \"gridDim.x = \" << blocks << \"\\n\";\n",
        "            std::cout << \"Total threads launched = \"\n",
        "                      << blocks * threads << \"\\n\";\n",
        "            std::cout << \"Kernel execution time (ms) = \"\n",
        "                      << milliseconds << \"\\n\";\n",
        "            std::cout << \"Result = \"\n",
        "                      << (pass ? \"PASS\" : \"FAIL\") << \"\\n\";\n",
        "            cudaEventDestroy(start);\n",
        "            cudaEventDestroy(stop);\n",
        "        }\n",
        "\n",
        "        cudaFree(d_A);\n",
        "        cudaFree(d_B);\n",
        "        cudaFree(d_C);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX5rjC0Ci1tk",
        "outputId": "d3ea7774-4960-4050-ff7b-32edea4d3ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu --gpu-architecture=native -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO4TYfoli45p",
        "outputId": "c9c6cf2e-c8f2-4f63-ecdc-f04161fdc9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "N = 1000\n",
            "blockDim.x = 32\n",
            "gridDim.x = 32\n",
            "Total threads launched = 1024\n",
            "Kernel execution time (ms) = 0.099936\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 1000\n",
            "blockDim.x = 128\n",
            "gridDim.x = 8\n",
            "Total threads launched = 1024\n",
            "Kernel execution time (ms) = 0.014304\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 1000\n",
            "blockDim.x = 256\n",
            "gridDim.x = 4\n",
            "Total threads launched = 1024\n",
            "Kernel execution time (ms) = 0.010816\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 1000\n",
            "blockDim.x = 512\n",
            "gridDim.x = 2\n",
            "Total threads launched = 1024\n",
            "Kernel execution time (ms) = 0.009888\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 100000\n",
            "blockDim.x = 32\n",
            "gridDim.x = 3125\n",
            "Total threads launched = 100000\n",
            "Kernel execution time (ms) = 0.016192\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 100000\n",
            "blockDim.x = 128\n",
            "gridDim.x = 782\n",
            "Total threads launched = 100096\n",
            "Kernel execution time (ms) = 0.01536\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 100000\n",
            "blockDim.x = 256\n",
            "gridDim.x = 391\n",
            "Total threads launched = 100096\n",
            "Kernel execution time (ms) = 0.014816\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 100000\n",
            "blockDim.x = 512\n",
            "gridDim.x = 196\n",
            "Total threads launched = 100352\n",
            "Kernel execution time (ms) = 0.016768\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 10000000\n",
            "blockDim.x = 32\n",
            "gridDim.x = 312500\n",
            "Total threads launched = 10000000\n",
            "Kernel execution time (ms) = 1.01155\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 10000000\n",
            "blockDim.x = 128\n",
            "gridDim.x = 78125\n",
            "Total threads launched = 10000000\n",
            "Kernel execution time (ms) = 0.469536\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 10000000\n",
            "blockDim.x = 256\n",
            "gridDim.x = 39063\n",
            "Total threads launched = 10000128\n",
            "Kernel execution time (ms) = 0.47184\n",
            "Result = PASS\n",
            "----------------------------------\n",
            "N = 10000000\n",
            "blockDim.x = 512\n",
            "gridDim.x = 19532\n",
            "Total threads launched = 10000384\n",
            "Kernel execution time (ms) = 0.4744\n",
            "Result = PASS\n"
          ]
        }
      ]
    }
  ]
}